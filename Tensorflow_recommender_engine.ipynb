{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd          \n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('C:/Users/chand/Downloads/Online Retail.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>536365</td>\n",
       "      <td>22752</td>\n",
       "      <td>SET 7 BABUSHKA NESTING BOXES</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>7.65</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>536365</td>\n",
       "      <td>21730</td>\n",
       "      <td>GLASS STAR FROSTED T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>536366</td>\n",
       "      <td>22633</td>\n",
       "      <td>HAND WARMER UNION JACK</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:28:00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>536366</td>\n",
       "      <td>22632</td>\n",
       "      <td>HAND WARMER RED POLKA DOT</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:28:00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>536367</td>\n",
       "      <td>84879</td>\n",
       "      <td>ASSORTED COLOUR BIRD ORNAMENT</td>\n",
       "      <td>32</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>1.69</td>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "5    536365     22752         SET 7 BABUSHKA NESTING BOXES         2   \n",
       "6    536365     21730    GLASS STAR FROSTED T-LIGHT HOLDER         6   \n",
       "7    536366     22633               HAND WARMER UNION JACK         6   \n",
       "8    536366     22632            HAND WARMER RED POLKA DOT         6   \n",
       "9    536367     84879        ASSORTED COLOUR BIRD ORNAMENT        32   \n",
       "\n",
       "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
       "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
       "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "5 2010-12-01 08:26:00       7.65     17850.0  United Kingdom  \n",
       "6 2010-12-01 08:26:00       4.25     17850.0  United Kingdom  \n",
       "7 2010-12-01 08:28:00       1.85     17850.0  United Kingdom  \n",
       "8 2010-12-01 08:28:00       1.85     17850.0  United Kingdom  \n",
       "9 2010-12-01 08:34:00       1.69     13047.0  United Kingdom  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvoiceNo           0\n",
       "StockCode           0\n",
       "Description      1454\n",
       "Quantity            0\n",
       "InvoiceDate         0\n",
       "UnitPrice           0\n",
       "CustomerID     135080\n",
       "Country             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking for NAs\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541909, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making columns names smaller\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On looking close at data some of the transaction are of return so we have to remove them\n",
    "## Also filling -1 where customerid is not present\n",
    "df = df[~df.invoiceno.astype('str').str.startswith('C')].reset_index(drop=True)\n",
    "df.customerid = df.customerid.fillna(-1).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we should encode all item IDs (stockcode) with integers\n",
    "stockcode_values = df.stockcode.astype('str')\n",
    "stockcodes = sorted(set(stockcode_values))\n",
    "stockcodes = {c: i for (i, c) in enumerate(stockcodes)}\n",
    "df.stockcode = stockcode_values.map(stockcodes).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoiceno</th>\n",
       "      <th>stockcode</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>invoicedate</th>\n",
       "      <th>unitprice</th>\n",
       "      <th>customerid</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>3527</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>2791</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>3040</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>2981</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>2980</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  invoiceno  stockcode                          description  quantity  \\\n",
       "0    536365       3527   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365       2791                  WHITE METAL LANTERN         6   \n",
       "2    536365       3040       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365       2981  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365       2980       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "          invoicedate  unitprice  customerid         country  \n",
       "0 2010-12-01 08:26:00       2.55       17850  United Kingdom  \n",
       "1 2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
       "2 2010-12-01 08:26:00       2.75       17850  United Kingdom  \n",
       "3 2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
       "4 2010-12-01 08:26:00       3.39       17850  United Kingdom  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.invoicedate < '2011-10-09']\n",
    "df_val = df[(df.invoicedate >= '2011-10-09') & \n",
    "            (df.invoicedate <= '2011-11-09') ]\n",
    "df_test = df[df.invoicedate >= '2011-11-09']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our evaluation measure is then the number of successful recommendations (the items the user has actually bought) divided by the number of total recommendations we made. This is called precision—a common measure of evaluating the performance of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First baseline is how many times a user has bought an item, then take the most frequent five items, and recommend these items to all the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = df_train.stockcode.value_counts().head(5).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3527, 3506, 1347, 2730,  180], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use this array to recommend it to all the users. So we repeat the top array as many times as there are transactions in the validation dataset, and then we use this as the recommendations and calculate the precision metric to evaluate the quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_groups = len(df_val.invoiceno.drop_duplicates())\n",
    "baseline = np.tile(top, num_groups).reshape(-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3527, 3506, 1347, 2730,  180],\n",
       "       [3527, 3506, 1347, 2730,  180],\n",
       "       [3527, 3506, 1347, 2730,  180],\n",
       "       ...,\n",
       "       [3527, 3506, 1347, 2730,  180],\n",
       "       [3527, 3506, 1347, 2730,  180],\n",
       "       [3527, 3506, 1347, 2730,  180]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to calculate the precision of this recommendation.However, there is a complication: the way the items are stored makes it difficult to calculate the number of correctly classified elements per group. Using groupby from pandas is one way of solving the problem.The reason it is slow is the way groupby is implemented in pandas: it internally performs sorting, which we do not need. However, we can improve the speed by exploiting the way the data is stored: we know that the elements of our dataframe are always ordered. That is, if a transaction starts at a certain row number i, then it ends at the number i + k, where k is the number of items in this transaction. In other words, all the rows between i and i + k belong to the same invoiceid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us call this array indptr. For each transaction t:  \n",
    "indptr[t] returns the number of the row in the dataframe where the transaction starts.  \n",
    "indptr[t + 1] returns the row where it ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532621, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoiceno</th>\n",
       "      <th>stockcode</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>invoicedate</th>\n",
       "      <th>unitprice</th>\n",
       "      <th>customerid</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>532616</th>\n",
       "      <td>581587</td>\n",
       "      <td>1526</td>\n",
       "      <td>PACK OF 20 SPACEBOY NAPKINS</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532617</th>\n",
       "      <td>581587</td>\n",
       "      <td>1802</td>\n",
       "      <td>CHILDREN'S APRON DOLLY GIRL</td>\n",
       "      <td>6</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532618</th>\n",
       "      <td>581587</td>\n",
       "      <td>2144</td>\n",
       "      <td>CHILDRENS CUTLERY DOLLY GIRL</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532619</th>\n",
       "      <td>581587</td>\n",
       "      <td>2145</td>\n",
       "      <td>CHILDRENS CUTLERY CIRCUS PARADE</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>4.15</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532620</th>\n",
       "      <td>581587</td>\n",
       "      <td>1092</td>\n",
       "      <td>BAKING SET 9 PIECE RETROSPOT</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-12-09 12:50:00</td>\n",
       "      <td>4.95</td>\n",
       "      <td>12680</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       invoiceno  stockcode                      description  quantity  \\\n",
       "532616    581587       1526      PACK OF 20 SPACEBOY NAPKINS        12   \n",
       "532617    581587       1802     CHILDREN'S APRON DOLLY GIRL          6   \n",
       "532618    581587       2144    CHILDRENS CUTLERY DOLLY GIRL          4   \n",
       "532619    581587       2145  CHILDRENS CUTLERY CIRCUS PARADE         4   \n",
       "532620    581587       1092    BAKING SET 9 PIECE RETROSPOT          3   \n",
       "\n",
       "               invoicedate  unitprice  customerid country  \n",
       "532616 2011-12-09 12:50:00       0.85       12680  France  \n",
       "532617 2011-12-09 12:50:00       2.10       12680  France  \n",
       "532618 2011-12-09 12:50:00       4.15       12680  France  \n",
       "532619 2011-12-09 12:50:00       4.15       12680  France  \n",
       "532620 2011-12-09 12:50:00       4.95       12680  France  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_indptr(df):\n",
    "    indptr, = np.where(df.invoiceno != df.invoiceno.shift())   \n",
    "    indptr = np.append(indptr, len(df)).astype('int32')\n",
    "    return indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     3,    32, ..., 63531, 64049, 64460])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting pointer arrays for validation\n",
    "val_indptr = group_indptr(df_val)\n",
    "val_indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 663, 2766,  810, ..., 1989, 2262, 2261])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.stockcode.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using numba for fast computation\n",
    "from numba import njit\n",
    "@njit\n",
    "def precision(group_indptr, true_items, predicted_items):\n",
    "    tp = 0    \n",
    "    n, m = predicted_items.shape    \n",
    "    for i in range(n):\n",
    "        group_start = group_indptr[i]\n",
    "        group_end = group_indptr[i + 1]\n",
    "        group_true_items = true_items[group_start:group_end]\n",
    "        for item in group_true_items: \n",
    "            for j in range(m):\n",
    "                if item == predicted_items[i, j]: \n",
    "                    tp = tp + 1   \n",
    "                    continue   \n",
    "    return tp / (n * m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check what is the precision of this baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0642299794661191"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_items = df_val.stockcode.values\n",
    "precision(val_indptr, val_items, baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing this code should produce 0.064. That is, in 6.4% of the cases we made the correct recommendation. This means that the user ended up buying the recommended item only in 6.4% cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we take a first look at the data and establish a simple baseline, we can proceed to more complex techniques such as matrix factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit baseline model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " we will establish another baseline have stronger than the previous one. We will use the implicit library, which uses ALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have already converted items (the column stockcode) to integers.\n",
    "# we need to perform the same on the user IDs (the column customerid):\n",
    "df_train_user = df_train[df_train.customerid != -1].reset_index(drop=True)\n",
    "customers = sorted(set(df_train_user.customerid))\n",
    "customers = {c: i for (i, c) in enumerate(customers)}\n",
    "df_train_user.customerid = df_train_user.customerid.map(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chand\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "## Doing same for validation data\n",
    "df_val.customerid = df_val.customerid.apply(lambda c: customers.get(c, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### we use these integer codes to construct the matrix X\n",
    "uid = df_train_user.customerid.values.astype('int32')\n",
    "iid = df_train_user.stockcode.values.astype('int32')\n",
    "ones = np.ones_like(uid, dtype='uint8')\n",
    "X_train = sp.csr_matrix((ones, (uid, iid)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us use implicit to factorize the matrix X and learn the user and item vectors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 15.0/15 [00:00<00:00, 23.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from implicit.als import AlternatingLeastSquares\n",
    "item_user = X_train.T.tocsr()\n",
    "als = AlternatingLeastSquares(factors=128, regularization=0.000001)\n",
    "als.fit(item_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_U = als.user_factors\n",
    "als_I = als.item_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix factorization methods have a problem: they cannot deal with new users. To overcome this problem, we can simply combine it with the baseline method: use the baseline to make a recommendation to new and unknown users, but apply Matrix Factorization to known users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_val = df_val.drop_duplicates(subset='invoiceno').customerid.values\n",
    "known_mask = uid_val != -1\n",
    "uid_val = uid_val[known_mask] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13782340862422998"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_baseline = baseline.copy()\n",
    "pred_all = als_U[uid_val].dot(als_I.T)\n",
    "top_val = (-pred_all).argsort(axis=1)[:, :5]\n",
    "imp_baseline[known_mask] = top_val\n",
    "precision(val_indptr, val_items, imp_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This outputs 14.1%. This is a lot stronger baseline than our previous baseline of 6.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Based Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us define a helper function for declaring embedding layers:\n",
    "def embed(inputs, size, dim, name=None):\n",
    "    std = np.sqrt(2 / dim)\n",
    "    emb = tf.Variable(tf.random_uniform([size, dim], -std, std), name=name) \n",
    "    lookup = tf.nn.embedding_lookup(emb, inputs)   \n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(?, 1) dtype=int32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.placeholder(tf.int32, shape=(None, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chand\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chand\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chand\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:514: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chand\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:514: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chand\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chand\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# parameters of the model\n",
    "num_users = uid.max() + 1\n",
    "num_items = iid.max() + 1\n",
    "num_factors = 128\n",
    "lambda_user = 0.0000001\n",
    "lambda_item = 0.0000001\n",
    "K = 5\n",
    "lr = 0.005\n",
    "graph = tf.Graph()\n",
    "graph.seed = 1\n",
    "with graph.as_default(): \n",
    "    # this is the input to the model\n",
    "    place_user = tf.placeholder(tf.int32, shape=(None, 1))  \n",
    "    place_item = tf.placeholder(tf.int32, shape=(None, 1))  \n",
    "    place_y = tf.placeholder(tf.float32, shape=(None, 1))   \n",
    "    # user features    \n",
    "    user_factors = embed(place_user, num_users, num_factors,         \"user_factors\") \n",
    "    user_bias = embed(place_user, num_users, 1, \"user_bias\")    \n",
    "    user_bias = tf.reshape(user_bias, [-1, 1])   \n",
    "    # item features    \n",
    "    item_factors = embed(place_item, num_items, num_factors,         \"item_factors\") \n",
    "    item_bias = embed(place_item, num_items, 1, \"item_bias\")   \n",
    "    item_bias = tf.reshape(item_bias, [-1, 1])  \n",
    "    global_bias = tf.Variable(0.0, name='global_bias')  \n",
    "    # prediction is dot product followed by a sigmoid    \n",
    "    pred = tf.reduce_sum(user_factors * item_factors, axis=2)  \n",
    "    pred = tf.sigmoid(global_bias + user_bias + item_bias + pred)   \n",
    "    reg = lambda_user * tf.reduce_sum(user_factors * user_factors) + lambda_item * tf.reduce_sum(item_factors * item_factors)    \n",
    "    # we have a classification model, so minimize logloss    \n",
    "    loss = tf.losses.log_loss(place_y, pred)    \n",
    "    loss_total = loss + reg   \n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr)    \n",
    "    step = opt.minimize(loss_total)    \n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now let us train the model. For that, we need to cut the input into small batches. Let us use a helper function for that:\n",
    "def prepare_batches(seq, step):\n",
    "    n = len(seq)    \n",
    "    res = []   \n",
    "    for i in range(0, n, step):\n",
    "        res.append(seq[i:i+step]) \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_variable(graph, session, name):\n",
    "    v = graph.get_operation_by_name(name) \n",
    "    v = v.values()[0]   \n",
    "    v = v.eval(session=session)   \n",
    "    return v\n",
    "def calculate_validation_precision(graph, session, uid): \n",
    "    U = get_variable(graph, session, 'user_factors')\n",
    "    I = get_variable(graph, session, 'item_factors') \n",
    "    bi = get_variable(graph, session, 'item_bias').reshape(-1)\n",
    "    pred_all = U[uid_val].dot(I.T) + bi    \n",
    "    top_val = (-pred_all).argsort(axis=1)[:, :5]    \n",
    "    imp_baseline = baseline.copy()    \n",
    "    imp_baseline[known_mask] = top_val\n",
    "    return precision(val_indptr, val_items, imp_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.538: 100%|███████████████████████████████████████████████████████████████████████████| 56/56 [00:03<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01: precision: 0.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.258: 100%|███████████████████████████████████████████████████████████████████████████| 56/56 [00:04<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 02: precision: 0.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.245: 100%|███████████████████████████████████████████████████████████████████████████| 56/56 [00:04<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 03: precision: 0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.221: 100%|███████████████████████████████████████████████████████████████████████████| 56/56 [00:04<00:00, 12.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 04: precision: 0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.201: 100%|███████████████████████████████████████████████████████████████████████████| 56/56 [00:04<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 05: precision: 0.137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.190: 100%|███████████████████████████████████████████████████████████████████████████| 56/56 [00:04<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 06: precision: 0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.176: 100%|███████████████████████████████████████████████████████████████████████████| 56/56 [00:03<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 07: precision: 0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.165: 100%|███████████████████████████████████████████████████████████████████████████| 56/56 [00:04<00:00, 14.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 08: precision: 0.150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.156: 100%|███████████████████████████████████████████████████████████████████████████| 56/56 [00:04<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 09: precision: 0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.152: 100%|███████████████████████████████████████████████████████████████████████████| 56/56 [00:04<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10: precision: 0.151\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session(config=None, graph=graph)\n",
    "session.run(init)\n",
    "np.random.seed(0)\n",
    "for i in range(10):\n",
    "    train_idx_shuffle = np.arange(uid.shape[0])\n",
    "    np.random.shuffle(train_idx_shuffle)   \n",
    "    batches = prepare_batches(train_idx_shuffle, 5000) \n",
    "    progress = tqdm(total=len(batches))    \n",
    "    for idx in batches:        \n",
    "        pos_samples = len(idx)    \n",
    "        neg_samples = pos_samples * K   \n",
    "        label = np.concatenate([np.ones(pos_samples, dtype='float32'), np.zeros(neg_samples, dtype='float32')]).reshape(-1, 1)\n",
    "        # negative sampling \n",
    "        neg_users = np.random.randint(low=0, high=num_users, size=neg_samples, dtype='int32')       \n",
    "        neg_items = np.random.randint(low=0, high=num_items,size=neg_samples, dtype='int32')     \n",
    "        batch_uid = np.concatenate([uid[idx], neg_users]).reshape(-1, 1)       \n",
    "        batch_iid = np.concatenate([iid[idx], neg_items]).reshape(-1, 1)      \n",
    "        feed_dict = {place_user: batch_uid,\n",
    "                     place_item: batch_iid,\n",
    "                     place_y: label }       \n",
    "        _, l = session.run([step, loss], feed_dict)       \n",
    "        progress.update(1)       \n",
    "        progress.set_description('%.3f' % l)   \n",
    "    progress.close()    \n",
    "    val_precision = calculate_validation_precision(graph, session, uid_val)\n",
    "    print('epoch %02d: precision: %.3f' % (i+1, val_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On 10 epoch it reaches 15.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Personalized Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_variable(size, dim, name=None):\n",
    "    std = np.sqrt(2 / dim)\n",
    "    return tf.Variable(tf.random_uniform([size, dim], -std, std), name=name)\n",
    "def embed(inputs, size, dim, name=None):  \n",
    "    emb = init_variable(size, dim, name) \n",
    "    return tf.nn.embedding_lookup(emb, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_factors = 128\n",
    "lambda_user = 0.0000001\n",
    "lambda_item = 0.0000001\n",
    "lambda_bias = 0.0000001\n",
    "lr = 0.0005\n",
    "graph = tf.Graph()\n",
    "graph.seed = 1\n",
    "with graph.as_default():\n",
    "    place_user = tf.placeholder(tf.int32, shape=(None, 1)) \n",
    "    place_item_pos = tf.placeholder(tf.int32, shape=(None, 1))  \n",
    "    place_item_neg = tf.placeholder(tf.int32, shape=(None, 1))  \n",
    "    # no place_y \n",
    "    user_factors = embed(place_user, num_users, num_factors,\"user_factors\")\n",
    "    # no user bias anymore as well as no global bias\n",
    "    item_factors = init_variable(num_items, num_factors,\"item_factors\")\n",
    "    item_factors_pos = tf.nn.embedding_lookup(item_factors, place_item_pos)  \n",
    "    item_factors_neg = tf.nn.embedding_lookup(item_factors, place_item_neg)   \n",
    "    item_bias = init_variable(num_items, 1, \"item_bias\")  \n",
    "    item_bias_pos = tf.nn.embedding_lookup(item_bias, place_item_pos) \n",
    "    item_bias_pos = tf.reshape(item_bias_pos, [-1, 1])  \n",
    "    item_bias_neg = tf.nn.embedding_lookup(item_bias, place_item_neg) \n",
    "    item_bias_neg = tf.reshape(item_bias_neg, [-1, 1])  \n",
    "    # predictions for each item are same as previously \n",
    "    # but no user bias and global bias   \n",
    "    pred_pos = item_bias_pos +  tf.reduce_sum(user_factors * item_factors_pos, axis=2)   \n",
    "    pred_neg = item_bias_neg + tf.reduce_sum(user_factors * item_factors_neg, axis=2) \n",
    "    pred_diff = pred_pos- pred_neg  \n",
    "    loss_bpr = -tf.reduce_mean(tf.log(tf.sigmoid(pred_diff)))  \n",
    "    loss_reg = lambda_user * tf.reduce_sum(user_factors * user_factors) +lambda_item * tf.reduce_sum(item_factors_pos * item_factors_pos)+ lambda_item * tf.reduce_sum(item_factors_neg * item_factors_neg)+lambda_bias * tf.reduce_sum(item_bias_pos) +lambda_bias * tf.reduce_sum(item_bias_neg) \n",
    "    loss_total = loss_bpr + loss_reg\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr) \n",
    "    step = opt.minimize(loss_total)   \n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01: precision: 0.022\n",
      "epoch 02: precision: 0.025\n",
      "epoch 03: precision: 0.027\n",
      "epoch 04: precision: 0.031\n",
      "epoch 05: precision: 0.035\n",
      "epoch 06: precision: 0.040\n",
      "epoch 07: precision: 0.045\n",
      "epoch 08: precision: 0.048\n",
      "epoch 09: precision: 0.051\n",
      "epoch 10: precision: 0.057\n",
      "epoch 11: precision: 0.060\n",
      "epoch 12: precision: 0.061\n",
      "epoch 13: precision: 0.063\n",
      "epoch 14: precision: 0.065\n",
      "epoch 15: precision: 0.067\n",
      "epoch 16: precision: 0.067\n",
      "epoch 17: precision: 0.069\n",
      "epoch 18: precision: 0.070\n",
      "epoch 19: precision: 0.073\n",
      "epoch 20: precision: 0.076\n",
      "epoch 21: precision: 0.077\n",
      "epoch 22: precision: 0.080\n",
      "epoch 23: precision: 0.083\n",
      "epoch 24: precision: 0.085\n",
      "epoch 25: precision: 0.087\n",
      "epoch 26: precision: 0.090\n",
      "epoch 27: precision: 0.092\n",
      "epoch 28: precision: 0.093\n",
      "epoch 29: precision: 0.095\n",
      "epoch 30: precision: 0.097\n",
      "epoch 31: precision: 0.099\n",
      "epoch 32: precision: 0.102\n",
      "epoch 33: precision: 0.103\n",
      "epoch 34: precision: 0.104\n",
      "epoch 35: precision: 0.107\n",
      "epoch 36: precision: 0.108\n",
      "epoch 37: precision: 0.109\n",
      "epoch 38: precision: 0.110\n",
      "epoch 39: precision: 0.110\n",
      "epoch 40: precision: 0.113\n",
      "epoch 41: precision: 0.113\n",
      "epoch 42: precision: 0.115\n",
      "epoch 43: precision: 0.118\n",
      "epoch 44: precision: 0.119\n",
      "epoch 45: precision: 0.120\n",
      "epoch 46: precision: 0.121\n",
      "epoch 47: precision: 0.122\n",
      "epoch 48: precision: 0.123\n",
      "epoch 49: precision: 0.123\n",
      "epoch 50: precision: 0.124\n",
      "epoch 51: precision: 0.125\n",
      "epoch 52: precision: 0.127\n",
      "epoch 53: precision: 0.128\n",
      "epoch 54: precision: 0.129\n",
      "epoch 55: precision: 0.129\n",
      "epoch 56: precision: 0.130\n",
      "epoch 57: precision: 0.131\n",
      "epoch 58: precision: 0.132\n",
      "epoch 59: precision: 0.134\n",
      "epoch 60: precision: 0.133\n",
      "epoch 61: precision: 0.134\n",
      "epoch 62: precision: 0.135\n",
      "epoch 63: precision: 0.135\n",
      "epoch 64: precision: 0.136\n",
      "epoch 65: precision: 0.137\n",
      "epoch 66: precision: 0.139\n",
      "epoch 67: precision: 0.139\n",
      "epoch 68: precision: 0.140\n",
      "epoch 69: precision: 0.139\n",
      "epoch 70: precision: 0.139\n",
      "epoch 71: precision: 0.140\n",
      "epoch 72: precision: 0.141\n",
      "epoch 73: precision: 0.141\n",
      "epoch 74: precision: 0.140\n",
      "epoch 75: precision: 0.142\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session(config=None, graph=graph)\n",
    "session.run(init)\n",
    "size_total = uid.shape[0]\n",
    "size_sample = 15000\n",
    "np.random.seed(0)\n",
    "for i in range(75):\n",
    "    for k in range(30):  \n",
    "        idx = np.random.randint(low=0, high=size_total, size=size_sample)  \n",
    "        batch_uid = uid[idx].reshape(-1, 1)        \n",
    "        batch_iid_pos = iid[idx].reshape(-1, 1)   \n",
    "        batch_iid_neg = np.random.randint(low=0, high=num_items, size=(size_sample, 1), dtype='int32')  \n",
    "        feed_dict = { place_user: batch_uid, \n",
    "                     place_item_pos: batch_iid_pos, \n",
    "                     place_item_neg: batch_iid_neg\n",
    "                    }        \n",
    "        _, l = session.run([step, loss_bpr], feed_dict)\n",
    "    val_precision = calculate_validation_precision(graph, session, uid_val) \n",
    "    print('epoch %02d: precision: %.3f' % (i+1, val_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 14.2%. So we will try RNN now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('C:/Users/chand/Downloads/Online Retail.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df = df[~df.invoiceno.astype('str').str.startswith('C')].reset_index(drop=True)\n",
    "df.customerid = df.customerid.fillna(-1).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder:\n",
    "    def fit(self, seq):\n",
    "        self.vocab = sorted(set(seq))\n",
    "        self.idx = {c: i + 1 for i, c in enumerate(self.vocab)}\n",
    "\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab) + 1\n",
    "\n",
    "    def transfrom(self, seq):\n",
    "        n = len(seq)\n",
    "        result = np.zeros(n, dtype='int32')\n",
    "\n",
    "        for i in range(n):\n",
    "            result[i] = self.idx.get(seq[i], 0)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def fit_transform(self, seq):\n",
    "        self.fit(seq)\n",
    "        return self.transfrom(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_enc = LabelEncoder()\n",
    "df.stockcode = item_enc.fit_transform(df.stockcode.astype('str'))\n",
    "df.stockcode = df.stockcode.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.invoicedate < '2011-10-09'].reset_index(drop=True)\n",
    "df_val = df[(df.invoicedate >= '2011-10-09') & (df.invoicedate <= '2011-11-09') ].reset_index(drop=True)\n",
    "df_test = df[df.invoicedate >= '2011-11-09'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((378470, 8), (64460, 8), (89691, 8))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_enc = LabelEncoder()\n",
    "user_enc.fit(df_train[df_train.customerid != -1].customerid)\n",
    "\n",
    "df_train.customerid = user_enc.transfrom(df_train.customerid)\n",
    "df_val.customerid = user_enc.transfrom(df_val.customerid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_train = df_train.drop_duplicates(subset='invoiceno').customerid.values\n",
    "uid_val = df_val.drop_duplicates(subset='invoiceno').customerid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_indptr(df):\n",
    "    indptr, = np.where(df.invoiceno != df.invoiceno.shift())\n",
    "    indptr = np.append(indptr, len(df)).astype('int32')\n",
    "    return indptr\n",
    "\n",
    "indptr_train = group_indptr(df_train)\n",
    "indptr_val = group_indptr(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "top_train = Counter(df_train.stockcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline(uid, indptr, items, top, k=5):\n",
    "    n_groups = len(uid)\n",
    "    n_items = len(items)\n",
    "\n",
    "    pred_all = np.zeros((n_items, k), dtype=np.int32)\n",
    "\n",
    "    for g in range(n_groups):\n",
    "        t = top.copy()\n",
    "\n",
    "        start = indptr[g]\n",
    "        end = indptr[g+1]\n",
    "        \n",
    "        for i in range(start, end):\n",
    "            pred = [k for (k, c) in t.most_common(5)]\n",
    "            pred_all[i] = pred\n",
    "\n",
    "            actual = items[i]\n",
    "            if actual in t:\n",
    "                del t[actual]\n",
    "\n",
    "    return pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid_val = df_val.stockcode.values\n",
    "pred_baseline = baseline(uid_val, indptr_val, iid_val, top_train, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3528, 3507, 1348, 2731,  181],\n",
       "       [3528, 3507, 1348, 2731,  181],\n",
       "       [3528, 3507, 1348, 2731,  181],\n",
       "       ...,\n",
       "       [1348, 2731,  181,  454, 1314],\n",
       "       [1348, 2731,  181,  454, 1314],\n",
       "       [1348, 2731,  181,  454, 1314]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def accuracy_k(y_true, y_pred):\n",
    "    n, k = y_pred.shape\n",
    "\n",
    "    acc = 0\n",
    "    for i in range(n):\n",
    "        for j in range(k):\n",
    "            if y_pred[i, j] == y_true[i]:\n",
    "                acc = acc + 1\n",
    "                break\n",
    "\n",
    "    return acc / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012705553831833695"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_k(iid_val, pred_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_items(users, items_indptr, items_vals):\n",
    "    n = len(items_indptr) - 1\n",
    "\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        start = items_indptr[i]\n",
    "        end = items_indptr[i+1]\n",
    "        result.append(items_vals[start:end])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_items = pack_items(indptr_train, indptr_train, df_train.stockcode.values)\n",
    "\n",
    "df_train_wrap = pd.DataFrame()\n",
    "df_train_wrap['customerid'] = uid_train\n",
    "df_train_wrap['items'] = train_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3439</td>\n",
       "      <td>[3528, 2792, 3041, 2982, 2981, 1662, 800]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3439</td>\n",
       "      <td>[1547, 1546]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>459</td>\n",
       "      <td>[3301, 1655, 1658, 1659, 1247, 3368, 1537, 153...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>[1862, 1816, 1815, 1817]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459</td>\n",
       "      <td>[818]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid                                              items\n",
       "0        3439          [3528, 2792, 3041, 2982, 2981, 1662, 800]\n",
       "1        3439                                       [1547, 1546]\n",
       "2         459  [3301, 1655, 1658, 1659, 1247, 3368, 1537, 153...\n",
       "3         459                           [1862, 1816, 1815, 1817]\n",
       "4         459                                              [818]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_wrap.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(data, num_steps):\n",
    "    data = np.pad(data, pad_width=(1, 0), mode='constant')\n",
    "\n",
    "    n = len(data)\n",
    "\n",
    "    if n <= num_steps:\n",
    "        pad_right = num_steps - n + 1\n",
    "        data = np.pad(data, pad_width=(0, pad_right), mode='constant')\n",
    "\n",
    "    return data\n",
    "\n",
    "def prepare_train_data(data, num_steps):\n",
    "    data = pad_seq(data, num_steps)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(num_steps, len(data)):\n",
    "        start = i - num_steps\n",
    "        X.append(data[start:i])\n",
    "        Y.append(data[start+1:i+1])\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "rnn = tf.contrib.rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    num_steps = 5\n",
    "\n",
    "    num_items = item_enc.vocab_size()\n",
    "    num_users = user_enc.vocab_size()\n",
    "\n",
    "    init_scale = 0.1\n",
    "    learning_rate = 1.0\n",
    "    max_grad_norm = 5\n",
    "    num_layers = 2\n",
    "    hidden_size = 200\n",
    "    embedding_size = 200\n",
    "    batch_size = 20    \n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_items = df_train_wrap['items']\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for i in range(len(train_items)):\n",
    "    X, Y = prepare_train_data(train_items[i], config.num_steps)\n",
    "    X_train.extend(X)\n",
    "    Y_train.extend(Y)\n",
    "\n",
    "X_train = np.array(X_train, dtype='int32')\n",
    "Y_train = np.array(Y_train, dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell(hidden_size, is_training):\n",
    "    return rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, \n",
    "                             state_is_tuple=True, reuse=not is_training)\n",
    "\n",
    "def rnn_model(inputs, hidden_size, num_layers, batch_size, num_steps, is_training):\n",
    "    cells = [lstm_cell(hidden_size, is_training) for _ in range(num_layers)]\n",
    "    cell = rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    inputs = tf.unstack(inputs, num=num_steps, axis=1)\n",
    "    outputs, final_state = rnn.static_rnn(cell, inputs, initial_state=initial_state)\n",
    "    output = tf.reshape(tf.concat(outputs, 1), [-1, hidden_size])\n",
    "\n",
    "    return output, initial_state, final_state\n",
    "\n",
    "\n",
    "def model(config, is_training):\n",
    "    batch_size = config.batch_size\n",
    "    num_steps = config.num_steps\n",
    "    embedding_size = config.embedding_size\n",
    "    hidden_size = config.hidden_size\n",
    "    num_items = config.num_items\n",
    "    place_x = tf.placeholder(shape=[batch_size, num_steps], dtype=tf.int32)\n",
    "    place_y = tf.placeholder(shape=[batch_size, num_steps], dtype=tf.int32)\n",
    "\n",
    "    embedding = tf.get_variable(\"items\", [num_items, embedding_size], dtype=tf.float32)\n",
    "    inputs = tf.nn.embedding_lookup(embedding, place_x)\n",
    "\n",
    "    output, initial_state, final_state = \\\n",
    "        rnn_model(inputs, hidden_size, config.num_layers, batch_size, num_steps, is_training)\n",
    "\n",
    "    W = tf.get_variable(\"W\", [hidden_size, num_items], dtype=tf.float32)\n",
    "    b = tf.get_variable(\"b\", [num_items], dtype=tf.float32)\n",
    "    logits = tf.nn.xw_plus_b(output, W, b)\n",
    "    logits = tf.reshape(logits, [batch_size, num_steps, num_items])\n",
    "\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(place_y, logits)\n",
    "    total_loss = tf.reduce_mean(loss)\n",
    "\n",
    "    tvars = tf.trainable_variables()\n",
    "    gradient = tf.gradients(total_loss, tvars)\n",
    "    clipped, _ = tf.clip_by_global_norm(gradient, config.max_grad_norm)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(config.learning_rate)\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    train_op = optimizer.apply_gradients(zip(clipped, tvars), global_step=global_step)\n",
    "    out = {}\n",
    "    out['place_x'] = place_x\n",
    "    out['place_y'] = place_y\n",
    "    \n",
    "    out['logits'] = logits\n",
    "    out['initial_state'] = initial_state\n",
    "    out['final_state'] = final_state\n",
    "\n",
    "    out['total_loss'] = total_loss\n",
    "    out['train_op'] = train_op\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-63-40ce7b637105>:3: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-63-40ce7b637105>:3: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-63-40ce7b637105>:7: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-63-40ce7b637105>:7: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-63-40ce7b637105>:11: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-63-40ce7b637105>:11: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "config_val = Config()\n",
    "config_val.batch_size = 1\n",
    "config_val.num_steps = 1\n",
    "\n",
    "graph = tf.Graph()\n",
    "graph.seed = 1\n",
    "\n",
    "with graph.as_default():\n",
    "    initializer = tf.random_uniform_initializer(-config.init_scale, config.init_scale)\n",
    "\n",
    "    with tf.name_scope(\"Train\"):\n",
    "        with tf.variable_scope(\"Model\", reuse=None, initializer=initializer):\n",
    "            train_model = model(config, is_training=True)\n",
    "\n",
    "    with tf.name_scope(\"Valid\"):\n",
    "        with tf.variable_scope(\"Model\", reuse=True, initializer=initializer):\n",
    "            val_model = model(config_val, is_training=False)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batches(seq, step):\n",
    "    n = len(seq)\n",
    "    res = []\n",
    "    for i in range(0, n, step):\n",
    "        res.append(seq[i:i+step])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(session, model, X, Y, batch_size):\n",
    "    fetches = {\n",
    "        \"total_loss\": model['total_loss'],\n",
    "        \"final_state\": model['final_state'],\n",
    "        \"eval_op\": model['train_op']\n",
    "    }\n",
    "\n",
    "    num_steps = X.shape[1]\n",
    "    all_idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(all_idx)\n",
    "    batches = prepare_batches(all_idx, batch_size)\n",
    "\n",
    "    initial_state = session.run(model['initial_state'])\n",
    "    current_state = initial_state\n",
    "\n",
    "    progress = tqdm(total=len(batches))\n",
    "    for idx in batches:\n",
    "        if len(idx) < batch_size:\n",
    "            continue\n",
    "\n",
    "        feed_dict = {}\n",
    "        for i, (c, h) in enumerate(model['initial_state']):\n",
    "            feed_dict[c] = current_state[i].c\n",
    "            feed_dict[h] = current_state[i].h\n",
    "\n",
    "        feed_dict[model['place_x']] = X[idx]\n",
    "        feed_dict[model['place_y']] = Y[idx]\n",
    "\n",
    "        vals = session.run(fetches, feed_dict)\n",
    "        loss = vals[\"total_loss\"]\n",
    "        current_state = vals[\"final_state\"]\n",
    "\n",
    "        progress.update(1)\n",
    "        progress.set_description('%.3f' % loss)\n",
    "    progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6.426: 100%|████████████████████████████████████████████████████████████████████▉| 16376/16377 [09:08<00:00, 29.87it/s]\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session(config=None, graph=graph) \n",
    "session.run(init)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "run_epoch(session, train_model, X_train, Y_train, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction(uid, indptr, items, model, k):\n",
    "    n_groups = len(uid)\n",
    "    n_items = len(items)\n",
    "\n",
    "    pred_all = np.zeros((n_items, k), dtype=np.int32)\n",
    "    initial_state = session.run(model['initial_state'])\n",
    "\n",
    "    fetches = {\n",
    "        \"logits\": model['logits'],\n",
    "        \"final_state\": model['final_state'],\n",
    "    }\n",
    "\n",
    "    for g in tqdm(range(n_groups)):    \n",
    "        start = indptr[g]\n",
    "        end = indptr[g+1]\n",
    "\n",
    "        current_state = initial_state\n",
    "\n",
    "        feed_dict = {}\n",
    "        for i, (c, h) in enumerate(model['initial_state']):\n",
    "            feed_dict[c] = current_state[i].c\n",
    "            feed_dict[h] = current_state[i].h\n",
    "\n",
    "        prev = np.array([[0]], dtype=np.int32)\n",
    "\n",
    "        for i in range(start, end):\n",
    "            feed_dict[model['place_x']] = prev\n",
    "\n",
    "            actual = items[i]\n",
    "            prev[0, 0] = actual\n",
    "\n",
    "            values = session.run(fetches, feed_dict)\n",
    "            current_state = values[\"final_state\"]\n",
    "\n",
    "            logits = values['logits'].reshape(-1)\n",
    "            pred = np.argpartition(-logits, k)[:k]\n",
    "            pred_all[i] = pred\n",
    "\n",
    "    return pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2435/2435 [01:08<00:00, 35.41it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_lstm = generate_prediction(uid_val, indptr_val, iid_val, val_model, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07053986968662737"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_k(iid_val, pred_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding user features to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "U_train = []\n",
    "Y_train = []\n",
    "\n",
    "\n",
    "for t in df_train_wrap.itertuples():\n",
    "    X, Y = prepare_train_data(t.items, config.num_steps)\n",
    "    U_train.extend([t.customerid] * len(X))\n",
    "    X_train.extend(X)\n",
    "    Y_train.extend(Y)\n",
    "\n",
    "X_train = np.array(X_train, dtype='int32')\n",
    "Y_train = np.array(Y_train, dtype='int32')\n",
    "U_train = np.array(U_train, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_model(config, is_training):\n",
    "    batch_size = config.batch_size\n",
    "    num_steps = config.num_steps\n",
    "    embedding_size = config.embedding_size\n",
    "    hidden_size = config.hidden_size\n",
    "    num_items = config.num_items\n",
    "    num_users = config.num_users\n",
    "\n",
    "    place_x = tf.placeholder(shape=[batch_size, num_steps], dtype=tf.int32)\n",
    "    place_u = tf.placeholder(shape=[batch_size, 1], dtype=tf.int32)\n",
    "    place_y = tf.placeholder(shape=[batch_size, num_steps], dtype=tf.int32)\n",
    "\n",
    "    item_embedding = tf.get_variable(\"items\", [num_items, embedding_size], dtype=tf.float32)\n",
    "    item_inputs = tf.nn.embedding_lookup(item_embedding, place_x)\n",
    "    \n",
    "    user_embedding = tf.get_variable(\"users\", [num_items, embedding_size], dtype=tf.float32)\n",
    "    u_repeat = tf.tile(place_u, [1, num_steps])\n",
    "    user_inputs = tf.nn.embedding_lookup(user_embedding, u_repeat)\n",
    "\n",
    "    inputs = tf.concat([user_inputs, item_inputs], axis=2)\n",
    "    \n",
    "    output, initial_state, final_state = \\\n",
    "        rnn_model(inputs, hidden_size, config.num_layers, batch_size, num_steps, is_training)\n",
    "\n",
    "    W = tf.get_variable(\"W\", [hidden_size, num_items], dtype=tf.float32)\n",
    "    b = tf.get_variable(\"b\", [num_items], dtype=tf.float32)\n",
    "\n",
    "    logits = tf.nn.xw_plus_b(output, W, b)\n",
    "    logits = tf.reshape(logits, [batch_size, num_steps, num_items])\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(place_y, logits)\n",
    "    total_loss = tf.reduce_mean(loss)\n",
    "\n",
    "    tvars = tf.trainable_variables()\n",
    "    gradient = tf.gradients(total_loss, tvars)\n",
    "    clipped, _ = tf.clip_by_global_norm(gradient, config.max_grad_norm)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(config.learning_rate)\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    train_op = optimizer.apply_gradients(zip(clipped, tvars), global_step=global_step)\n",
    "\n",
    "    out = {}\n",
    "    out['place_x'] = place_x\n",
    "    out['place_u'] = place_u\n",
    "    out['place_y'] = place_y\n",
    "    \n",
    "\n",
    "    out['logits'] = logits\n",
    "    out['initial_state'] = initial_state\n",
    "    out['final_state'] = final_state\n",
    "\n",
    "    out['total_loss'] = total_loss\n",
    "    out['train_op'] = train_op\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "graph.seed = 1\n",
    "\n",
    "with graph.as_default():\n",
    "    initializer = tf.random_uniform_initializer(-config.init_scale, config.init_scale)\n",
    "\n",
    "    with tf.name_scope(\"Train\"):\n",
    "        with tf.variable_scope(\"Model\", reuse=None, initializer=initializer):\n",
    "            train_model = user_model(config, is_training=True)\n",
    "\n",
    "    with tf.name_scope(\"Valid\"):\n",
    "        with tf.variable_scope(\"Model\", reuse=True, initializer=initializer):\n",
    "            val_model = user_model(config_val, is_training=False)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "session = tf.Session(config=None, graph=graph) \n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "def user_model_epoch(session, model, X, U, Y, batch_size):\n",
    "    fetches = {\n",
    "        \"total_loss\": model['total_loss'],\n",
    "        \"final_state\": model['final_state'],\n",
    "        \"eval_op\": model['train_op']\n",
    "    }\n",
    "\n",
    "    num_steps = X.shape[1]\n",
    "    all_idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(all_idx)\n",
    "    batches = prepare_batches(all_idx, batch_size)\n",
    "\n",
    "    initial_state = session.run(model['initial_state'])\n",
    "    current_state = initial_state\n",
    "\n",
    "    progress = tqdm(total=len(batches))\n",
    "    for idx in batches:\n",
    "        if len(idx) < batch_size:\n",
    "            continue\n",
    "\n",
    "        feed_dict = {}\n",
    "        for i, (c, h) in enumerate(model['initial_state']):\n",
    "            feed_dict[c] = current_state[i].c\n",
    "            feed_dict[h] = current_state[i].h\n",
    "\n",
    "        feed_dict[model['place_x']] = X[idx]\n",
    "        feed_dict[model['place_y']] = Y[idx]\n",
    "        feed_dict[model['place_u']] = U[idx].reshape(-1, 1)\n",
    "\n",
    "        vals = session.run(fetches, feed_dict)\n",
    "        loss = vals[\"total_loss\"]\n",
    "        current_state = vals[\"final_state\"]\n",
    "\n",
    "        progress.update(1)\n",
    "        progress.set_description('%.3f' % loss)\n",
    "    progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5.789: 100%|████████████████████████████████████████████████████████████████████▉| 16376/16377 [10:22<00:00, 26.29it/s]\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session(config=None, graph=graph) \n",
    "session.run(init)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "user_model_epoch(session, train_model, X_train, U_train, Y_train, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_user_model(uid, indptr, items, model, k):\n",
    "    n_groups = len(uid)\n",
    "    n_items = len(items)\n",
    "\n",
    "    pred_all = np.zeros((n_items, k), dtype=np.int32)\n",
    "    initial_state = session.run(model['initial_state'])\n",
    "\n",
    "    fetches = {\n",
    "        \"logits\": model['logits'],\n",
    "        \"final_state\": model['final_state'],\n",
    "    }\n",
    "\n",
    "    for g in tqdm(range(n_groups)):    \n",
    "        start = indptr[g]\n",
    "        end = indptr[g+1]\n",
    "        u = uid[g]\n",
    "\n",
    "        current_state = initial_state\n",
    "\n",
    "        feed_dict = {}\n",
    "        feed_dict[model['place_u']] = np.array([[u]], dtype=np.int32)\n",
    "\n",
    "        for i, (c, h) in enumerate(model['initial_state']):\n",
    "            feed_dict[c] = current_state[i].c\n",
    "            feed_dict[h] = current_state[i].h\n",
    "\n",
    "        prev = np.array([[0]], dtype=np.int32)\n",
    "        for i in range(start, end):\n",
    "            feed_dict[model['place_x']] = prev\n",
    "\n",
    "            actual = items[i]\n",
    "            prev[0, 0] = actual\n",
    "\n",
    "            values = session.run(fetches, feed_dict)\n",
    "            current_state = values[\"final_state\"]\n",
    "\n",
    "            logits = values['logits'].reshape(-1)\n",
    "            pred = np.argpartition(-logits, k)[:k]\n",
    "            pred_all[i] = pred\n",
    "\n",
    "    return pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2435/2435 [01:09<00:00, 35.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22804840210983557"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lstm = generate_prediction_user_model(uid_val, indptr_val, iid_val, val_model, k=5)\n",
    "accuracy_k(iid_val, pred_lstm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
